<!doctype html>
<html>
  <head>
    <meta charset="UTF-8" />
    <title>Dictation</title>
    <style>
      * {
        margin: 0;
        padding: 0;
        box-sizing: border-box;
      }

      html {
        background: transparent;
      }

      body {
        font-family: -apple-system, BlinkMacSystemFont, "SF Pro Display",
          "Helvetica Neue", Arial, sans-serif;
        color-scheme: light dark;
        background: rgba(250, 250, 252, 0.06);
        border-radius: 12px;
        border: 1px solid rgba(255, 255, 255, 0.35);
        box-shadow:
          0 12px 48px rgba(0, 0, 0, 0.2),
          0 2px 10px rgba(0, 0, 0, 0.08);
        overflow: hidden;
        user-select: none;
        -webkit-user-select: none;
        transition:
          opacity 0.25s cubic-bezier(0.4, 0, 0.2, 1),
          transform 0.25s cubic-bezier(0.4, 0, 0.2, 1),
          box-shadow 0.2s ease,
          border-color 0.2s ease,
          background 0.2s ease;
        background-clip: padding-box;
        opacity: 0;
        transform: scale(0.95) translateY(10px);
      }

      body.visible {
        opacity: 1;
        transform: scale(1) translateY(0);
      }

      body:hover {
        box-shadow:
          0 14px 56px rgba(0, 0, 0, 0.22),
          0 6px 16px rgba(0, 0, 0, 0.1);
      }

      .dictation-container {
        padding: 12px 16px;
        display: flex;
        align-items: center;
        gap: 12px;
        height: 48px;
        min-height: 48px;
        max-height: 48px;
        -webkit-app-region: drag; /* Make the entire container draggable */
        cursor: grab;
        transition: cursor 0.2s ease;
      }

      .dictation-container:active {
        cursor: grabbing;
      }

      /* Make interactive elements non-draggable */
      .status-icon,
      .close-button,
      .text-scroll-container {
        -webkit-app-region: no-drag;
        cursor: default;
      }

      .close-button {
        cursor: pointer;
      }

      .text-scroll-container {
        cursor: text;
      }

      .status-icon {
        width: 24px;
        height: 24px;
        border-radius: 50%;
        display: flex;
        align-items: center;
        justify-content: center;
        flex-shrink: 0;
        transition: all 0.3s ease;
        /* stronger, simple border + shadow for better contrast */
        border: 1px solid rgba(0, 0, 0, 0.08);
        box-shadow: 0 1px 2px rgba(0, 0, 0, 0.14);
      }

      .status-icon.recording {
        background: rgba(255, 105, 97, 0.92);
        animation: pulse 1.5s infinite;
      }

      .status-icon.idle {
        background: rgba(52, 199, 89, 0.92);
      }

      .status-icon.transcribing,
      .status-icon.transforming,
      .status-icon.injecting {
        background: rgba(255, 159, 10, 0.92);
      }

      .status-icon.complete {
        background: rgba(52, 199, 89, 0.92);
      }

      .status-icon svg {
        width: 14px;
        height: 14px;
        fill: white;
      }

      .text-scroll-container {
        flex: 1;
        overflow-x: auto;
        overflow-y: hidden;
        position: relative;
        height: 24px;
        display: flex;
        align-items: center;
        scrollbar-width: none;
        -ms-overflow-style: none;
      }

      .text-scroll-container::-webkit-scrollbar {
        display: none;
      }

      .wave-container {
        position: absolute;
        top: 0;
        left: 0;
        right: 0;
        bottom: 0;
        display: flex;
        align-items: center;
        justify-content: center;
        opacity: 0;
        transition: opacity 0.25s ease;
        pointer-events: none;
      }

      .wave-container.active {
        opacity: 1;
      }

      .wave-canvas {
        width: 100%;
        height: 24px;
        image-rendering: pixelated;
      }

      .text-content {
        display: flex;
        align-items: baseline;
        gap: 4px;
        white-space: nowrap;
        min-width: 100%;
        line-height: 1.2;
      }

      .text-segment {
        font-size: 13px;
        color: #0b0b0c66; /* increased contrast */
        font-weight: 300;
        display: inline-block;
        line-height: 1.2;
        text-shadow: none; /* remove soft glow to improve legibility */
      }

      .text-segment.transcribed {
        color: #0b0b0c;
      }

      .text-segment.in-progress {
        color: #6b6b70; /* darker grey for better contrast */
      }

      .text-segment.in-progress::after {
        content: "|";
        animation: blink 1.2s ease-in-out infinite;
        margin-left: 1px;
        font-weight: 300;
        vertical-align: baseline;
        line-height: 1.2;
      }

      .text-segment.in-progress.no-caret::after {
        content: none;
      }

      .in-progress-spinner {
        width: 14px;
        height: 14px;
        animation: spin 0.9s linear infinite;
        display: inline-block;
        vertical-align: text-bottom;
      }

      .separator {
        color: #6e6e73;
        font-size: 12px;
        margin: 0 4px;
        text-shadow: none;
      }

      @keyframes pulse {
        0% {
          transform: scale(1);
          opacity: 1;
        }
        50% {
          transform: scale(1.1);
          opacity: 0.8;
        }
        100% {
          transform: scale(1);
          opacity: 1;
        }
      }

      @keyframes spin {
        0% {
          transform: rotate(0deg);
        }
        100% {
          transform: rotate(360deg);
        }
      }

      @keyframes fastSpin {
        0% {
          transform: rotate(0deg);
        }
        100% {
          transform: rotate(360deg);
        }
      }

      .status-icon.transcribing svg,
      .status-icon.transforming svg,
      .status-icon.injecting svg {
        animation: fastSpin 0.6s linear infinite;
      }

      @keyframes blink {
        0% {
          opacity: 1;
        }
        50% {
          opacity: 0.3;
        }
        100% {
          opacity: 1;
        }
      }

      .close-button {
        width: 20px;
        height: 20px;
        border-radius: 50%;
        background: rgba(255, 59, 48, 0.35);
        border: none;
        cursor: pointer;
        display: flex;
        align-items: center;
        justify-content: center;
        transition: all 0.2s ease;
        flex-shrink: 0;
        box-shadow:
          inset 0 0 0 0.5px rgba(255, 255, 255, 0.6),
          0 1px 2px rgba(0, 0, 0, 0.08);
      }

      .close-button:hover {
        background: rgba(255, 69, 58, 0.5);
        transform: translateY(-0.5px);
      }

      .close-button svg {
        width: 10px;
        height: 10px;
        fill: white;
      }

      @media (prefers-color-scheme: dark) {
        body {
          background: rgba(30, 30, 30, 0.5);
          border-color: rgba(255, 255, 255, 0.12);
          box-shadow:
            0 20px 60px rgba(0, 0, 0, 0.5),
            0 6px 18px rgba(0, 0, 0, 0.3);
          background-image: linear-gradient(
            to bottom,
            rgba(255, 255, 255, 0.06),
            rgba(255, 255, 255, 0.02)
          );
        }

        body:hover {
          box-shadow:
            0 22px 70px rgba(0, 0, 0, 0.55),
            0 8px 22px rgba(0, 0, 0, 0.35);
        }

        .text-segment {
          color: #f2f2f7;
          text-shadow: 0 1px 1px rgba(0, 0, 0, 0.35);
        }

        .text-segment.transcribed {
          color: #f2f2f7;
        }

        .text-segment.in-progress {
          color: #8e8e93;
        }

        .separator {
          color: #8e8e93;
          text-shadow: 0 1px 1px rgba(0, 0, 0, 0.25);
        }
      }

      @media (prefers-reduced-transparency: reduce) {
        body {
          backdrop-filter: none;
          -webkit-backdrop-filter: none;
          background: #f5f5f7;
          border-color: rgba(0, 0, 0, 0.1);
        }
        @media (prefers-color-scheme: dark) {
          body {
            background: #1c1c1e;
            border-color: rgba(255, 255, 255, 0.12);
          }
        }
      }
    </style>
  </head>
  <body>
    <div id="app">
      <div class="dictation-container">
        <div class="status-icon" :class="currentStatus">
          <!-- Microphone icon for idle and recording states -->
          <svg
            v-if="currentStatus === 'idle' || currentStatus === 'recording'"
            viewBox="0 0 256 256"
          >
            <path
              fill="currentColor"
              d="M128 174a46.06 46.06 0 0 0 46-46V64a46 46 0 0 0-92 0v64a46.06 46.06 0 0 0 46 46M94 64a34 34 0 0 1 68 0v64a34 34 0 0 1-68 0Zm40 141.75V240a6 6 0 0 1-12 0v-34.25A78.09 78.09 0 0 1 50 128a6 6 0 0 1 12 0a66 66 0 0 0 132 0a6 6 0 0 1 12 0a78.09 78.09 0 0 1-72 77.75"
            />
          </svg>

          <!-- Loading spinner for processing states -->
          <svg
            v-else-if="currentStatus === 'transcribing' || currentStatus === 'transforming' || currentStatus === 'injecting'"
            viewBox="0 0 24 24"
          >
            <g fill="none" fill-rule="evenodd">
              <path
                d="m12.593 23.258l-.011.002l-.071.035l-.02.004l-.014-.004l-.071-.035q-.016-.005-.024.005l-.004.01l-.017.428l.005.02l.01.013l.104.074l.015.004l.012-.004l.104-.074l.012-.016l.004-.017l-.017-.427q-.004-.016-.017-.018m.265-.113l-.013.002l-.185.093l-.01.01l-.003.011l.018.43l.005.012l.008.007l.201.093q.019.005.029-.008l.004-.014l-.034-.614q-.005-.018-.02-.022m-.715.002a.02.02 0 0 0-.027.006l-.006.014l-.034.614q.001.018.017.024l.015-.002l.201-.093l.01-.008l.004-.011l.017-.43l-.003-.012l-.01-.01z"
              />
              <path
                fill="currentColor"
                d="M12 4a8 8 0 1 0 0 16a8 8 0 0 0 0-16M2 12C2 6.477 6.477 2 12 2s10 4.477 10 10s-4.477 10-10 10S2 17.523 2 12"
                opacity=".1"
              />
              <path
                fill="currentColor"
                d="M12 4a7.96 7.96 0 0 0-5.533 2.222a1 1 0 1 1-1.384-1.444A9.96 9.96 0 0 1 12 2a1 1 0 1 1 0 2"
              />
            </g>
          </svg>

          <!-- Check icon for complete state -->
          <svg v-else-if="currentStatus === 'complete'" viewBox="0 0 256 256">
            <path
              fill="currentColor"
              d="m229.66 77.66l-128 128a8 8 0 0 1-11.32 0l-56-56a8 8 0 0 1 11.32-11.32L96 188.69L218.34 66.34a8 8 0 0 1 11.32 11.32"
            />
          </svg>
        </div>

        <div class="text-scroll-container" ref="textScrollContainer">
          <div class="wave-container" :class="{ active: showVisualizer }">
            <canvas id="waveCanvas" class="wave-canvas" height="24"></canvas>
          </div>
          <div class="text-content" ref="textContent">
            <span
              v-for="(segment, index) in displaySegments"
              :key="segment.id || index"
              v-if="!showVisualizer"
              class="text-segment"
              :class="[getSegmentClass(segment), segment.type === 'inprogress' ? 'no-caret' : '']"
            >
              <template v-if="segment.type === 'inprogress'">
                <template v-if="showInProgressSpinner.text">
                  {{ getSegmentDisplayText(segment) }}
                </template>
                <svg
                  v-if="showInProgressSpinner.show"
                  class="in-progress-spinner"
                  xmlns="http://www.w3.org/2000/svg"
                  viewBox="0 0 256 256"
                >
                  <path
                    fill="currentColor"
                    d="M134 32v32a6 6 0 0 1-12 0V32a6 6 0 0 1 12 0m39.25 56.75A6 6 0 0 0 177.5 87l22.62-22.63a6 6 0 0 0-8.48-8.48L169 78.5a6 6 0 0 0 4.24 10.25ZM224 122h-32a6 6 0 0 0 0 12h32a6 6 0 0 0 0-12m-46.5 47a6 6 0 0 0-8.5 8.5l22.63 22.62a6 6 0 0 0 8.48-8.48ZM128 186a6 6 0 0 0-6 6v32a6 6 0 0 0 12 0v-32a6 6 0 0 0-6-6m-49.5-17l-22.62 22.64a6 6 0 1 0 8.48 8.48L87 177.5a6 6 0 1 0-8.5-8.5M70 128a6 6 0 0 0-6-6H32a6 6 0 0 0 0 12h32a6 6 0 0 0 6-6m-5.64-72.12a6 6 0 0 0-8.48 8.48L78.5 87a6 6 0 1 0 8.5-8.5Z"
                  />
                </svg>
              </template>
              <template v-else> {{ getSegmentDisplayText(segment) }} </template>
            </span>
            <span
              v-if="displaySegments.length === 0 && (currentStatus === 'transcribing' || currentStatus === 'transforming' || currentStatus === 'injecting') && !showVisualizer"
              class="text-segment in-progress"
              >Processing...</span
            >
            <span
              v-else-if="displaySegments.length === 0"
              class="text-segment in-progress"
              style="opacity: 0"
              >&nbsp;</span
            >
          </div>
        </div>

        <button class="close-button" @click="handleClose">
          <!-- X icon using Phosphor -->
          <svg viewBox="0 0 256 256">
            <path
              d="M205.66,194.34a8,8,0,0,1-11.32,11.32L128,139.31,61.66,205.66a8,8,0,0,1-11.32-11.32L116.69,128,50.34,61.66A8,8,0,0,1,61.66,50.34L128,116.69l66.34-66.35a8,8,0,0,1,11.32,11.32L139.31,128Z"
            />
          </svg>
        </button>
      </div>
    </div>
    <!-- Audio elements for sound feedback -->
    <audio id="startSound" preload="auto">
      <source src="../assets/start.mp3" type="audio/mpeg" />
    </audio>
    <audio id="endSound" preload="auto">
      <source src="../assets/end.mp3" type="audio/mpeg" />
    </audio>
    <!-- Silero VAD Libraries (local) -->
    <script src="./ort.js"></script>
    <script src="./bundle.min.js"></script>
    <script src="./vue.js"></script>
    <script src="./audio-visualizer.js"></script>
    <script>
      const { createApp, ref, computed, onMounted, nextTick, watch } = Vue;

      createApp({
        setup() {
          // Reactive state
          const isRecording = ref(false);
          const currentStatus = ref("idle");
          const transcriptionSegments = ref([]);
          const finalText = ref("");
          const currentAudioLevel = ref(0);
          const isRunOnAllPlugin = ref(false);
          const selectedText = ref("");

          const isSpeaking = ref(false);

          const showInProgressSpinner = computed(() => {
            const completedSegments = transcriptionSegments.value.filter(
              (s) => s.type === "transcribed" && s.completed,
            );
            const inProgressSegments = transcriptionSegments.value.filter(
              (s) => s.type === "inprogress",
            );
            return {
              show: inProgressSegments.length > 0,
              text: completedSegments.length == 0,
            };
          });

          const showVisualizer = computed(() => {
            const isProcessing = [
              "transcribing",
              "transforming",
              "injecting",
            ].includes(currentStatus.value);
            if (
              isProcessing ||
              currentStatus.value === "complete" ||
              currentStatus.value === "idle"
            ) {
              return false;
            }

            if (currentStatus.value !== "recording") {
              return false;
            }

            const hasInProgressSegments = transcriptionSegments.value.some(
              (s) => s.type === "inprogress" || !s.completed,
            );
            if (hasInProgressSegments) {
              return false;
            }

            if (transcriptionSegments.value.length > 0) {
              return isSpeaking.value;
            }

            return true;
          });

          const hasTranscription = computed(() => {
            return transcriptionSegments.value.length > 0 || finalText.value;
          });

          const displaySegments = computed(() => {
            if (finalText.value) {
              return [
                { type: "transcribed", text: finalText.value, completed: true },
              ];
            }

            const segments = transcriptionSegments.value;
            const completedSegments = segments.filter(
              (segment) => segment.type === "transcribed" && segment.completed,
            );

            const lastInProgressSegment = segments
              .filter(
                (segment) =>
                  segment.type === "inprogress" ||
                  (!segment.completed && segment.type === "transcribed"),
              )
              .pop();

            const result = [...completedSegments];
            if (lastInProgressSegment) {
              result.push(lastInProgressSegment);
            }

            return result;
          });

          const textContent = ref(null);
          const textScrollContainer = ref(null);
          let visualizer = null;
          let resizeObserver = null;

          // VAD state
          const vadInstance = ref(null);
          const isVadInitialized = ref(false);
          const mediaStream = ref(null);
          let audioContext = null;
          let analyser = null;
          let sourceNode = null;
          let rmsArray = null;

          const scrollToEnd = () => {
            if (textScrollContainer.value) {
              textScrollContainer.value.scrollLeft =
                textScrollContainer.value.scrollWidth;
            }
          };

          // Methods
          const resetTranscription = () => {
            transcriptionSegments.value = [];
            finalText.value = "";
            currentAudioLevel.value = 0;
          };

          // Sound feedback
          const playStartSound = () => {
            try {
              const startSound = document.getElementById("startSound");
              if (startSound) {
                startSound.volume = 0.8;
                startSound.play().catch(() => {});
              }
            } catch (_) {}
          };

          const playEndSound = () => {
            try {
              const endSound = document.getElementById("endSound");
              if (endSound) {
                endSound.volume = 0.8;
                endSound.play().catch(() => {});
              }
            } catch (_) {}
          };

          const getSegmentClass = (segment) => {
            if (segment.type === "transcribed") {
              return segment.completed ? "transcribed" : "in-progress";
            }
            if (segment.type === "inprogress") return "in-progress";
            return "";
          };

          const getSegmentDisplayText = (segment) => {
            return segment.text;
          };

          setInterval(() => {
            if (analyser && rmsArray) {
              try {
                analyser.getFloatTimeDomainData(rmsArray);
                let sum = 0;
                for (let i = 0; i < rmsArray.length; i++) {
                  const v = rmsArray[i];
                  sum += v * v;
                }
                const rms = Math.sqrt(sum / rmsArray.length);
                const scaled = Math.min(1, rms * 8);
                currentAudioLevel.value = scaled;
              } catch (_) {}
            }
          }, 50);

          const handleClose = () => {
            disableVADStream();
            playEndSound();
            window.electronAPI.closeDictationWindow();
          };

          // VAD Methods
          const initializeVAD = async () => {
            try {
              if (!window.vad) throw new Error("VAD library not loaded");
              const stream = await navigator.mediaDevices.getUserMedia({
                audio: {
                  sampleRate: 16000,
                  channelCount: 1,
                  echoCancellation: true,
                  noiseSuppression: true,
                },
              });
              mediaStream.value = stream;
              stream.getAudioTracks().forEach((track) => (track.enabled = false));
              const myVAD = await window.vad.MicVAD.new({
                baseAssetPath: "./",
                onnxWASMBasePath: "./",
                model: "v5",
                positiveSpeechThreshold: 0.5,
                negativeSpeechThreshold: 0.35,
                preSpeechPadFrames: 40,
                redemptionFrames: 10,
                frameSamples: 512,
                minSpeechFrames: 3,
                submitUserSpeechOnPause: true,
                stream: stream,
                onSpeechStart: () => {
                  isSpeaking.value = true;
                },
                onSpeechEnd: (audio) => {
                  isSpeaking.value = false;
                  if (isRecording.value && audio.length > 0) {
                    window.electronAPI.sendAudioSegment(audio);
                  }
                },
              });
              vadInstance.value = myVAD;
              isVadInitialized.value = true;
              await startVAD();
            } catch (error) {
              console.error("Failed to initialize VAD:", error);
            }
          };

          const startVAD = async () => {
            if (!isVadInitialized.value) await initializeVAD();
            if (vadInstance.value) await vadInstance.value.start();
          };

          const enableVADStream = async () => {
            if (mediaStream.value) {
              mediaStream.value.getAudioTracks().forEach((track) => (track.enabled = true));
              if (!audioContext) audioContext = new (window.AudioContext || window.webkitAudioContext)();
              if (sourceNode) sourceNode.disconnect();
              sourceNode = audioContext.createMediaStreamSource(mediaStream.value);
              analyser = audioContext.createAnalyser();
              analyser.fftSize = 512;
              rmsArray = new Float32Array(analyser.fftSize);
              sourceNode.connect(analyser);
            }
          };

          const disableVADStream = async () => {
            if (mediaStream.value) {
              mediaStream.value.getAudioTracks().forEach((track) => (track.enabled = false));
            }
            if (sourceNode) sourceNode.disconnect();
            sourceNode = null;
            analyser = null;
            rmsArray = null;
          };

          const stopVAD = async () => {
            if (vadInstance.value) await vadInstance.value.pause();
          };

          const cleanupMediaStream = () => {
            if (mediaStream.value) {
              mediaStream.value.getTracks().forEach((track) => track.stop());
              mediaStream.value = null;
            }
          };

          // IPC event handlers
          const initializeDictation = (data) => {
            selectedText.value = data.selectedText || "";
            isRunOnAllPlugin.value = data.isRunOnAll || false;
            resetTranscription();
          };

          const startRecording = async () => {
            isRecording.value = true;
            resetTranscription();
            await enableVADStream();
            nextTick(setupVisualizer);
          };

          const stopRecording = async () => {
            isRecording.value = false;
            await disableVADStream();
            teardownVisualizer();
          };

          const updateTranscription = (update) => {
            transcriptionSegments.value = update.segments;
          };

          const completeDictation = (text) => {
            finalText.value = text;
            transcriptionSegments.value = [{ type: "transcribed", text, completed: true }];
          };

          const clearDictation = () => {
            isRecording.value = false;
            resetTranscription();
          };

          watch([displaySegments], () => nextTick(scrollToEnd));

          onMounted(async () => {
            window.electronAPI.onAnimateIn(() => {
              document.body.classList.add("visible");
              playStartSound();
              enableVADStream();
            });
            window.electronAPI.onInitializeDictation(initializeDictation);
            window.electronAPI.onStartRecording(startRecording);
            window.electronAPI.onStopRecording(stopRecording);
            window.electronAPI.onTranscriptionUpdate(updateTranscription);
            window.electronAPI.onDictationComplete(completeDictation);
            window.electronAPI.onDictationClear(clearDictation);
            window.electronAPI.onSetStatus((status) => (currentStatus.value = status));
            window.electronAPI.onPlayEndSound(playEndSound);
            setupVisualizer();
            document.addEventListener("dragstart", (e) => e.preventDefault());
            window.addEventListener("beforeunload", () => {
              playEndSound();
              cleanupMediaStream();
            });
            await initializeVAD();
          });

          function setupVisualizer() {
            const container = textScrollContainer.value;
            const canvas = document.getElementById("waveCanvas");
            if (!container || !canvas) return;
            canvas.width = container.offsetWidth;
            if (!visualizer) {
              visualizer = window.createAudioVisualizer(canvas, {
                getLevel: () => currentAudioLevel.value,
                bars: 64,
                smoothing: 0.6,
              });
              visualizer.start();
            }
            if (!resizeObserver) {
              resizeObserver = new ResizeObserver(() => {
                canvas.width = container.offsetWidth;
                if (visualizer) visualizer.resize();
              });
              resizeObserver.observe(container);
            }
          }

          function teardownVisualizer() {}

          return {
            isRecording,
            currentStatus,
            transcriptionSegments,
            finalText,
            showVisualizer,
            isRunOnAllPlugin,
            selectedText,
            statusIconClass: computed(() => currentStatus.value),
            hasTranscription,
            displaySegments,
            textContent,
            textScrollContainer,
            showInProgressSpinner,
            resetTranscription,
            getSegmentClass,
            getSegmentDisplayText,
            handleClose,
          };
        },
      }).mount("#app");
    </script>
  </body>
</html>
