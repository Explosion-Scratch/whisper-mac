<!DOCTYPE html>
<html>
  <head>
    <meta charset="UTF-8" />
    <title>Dictation</title>
    <style>
      * {
        margin: 0;
        padding: 0;
        box-sizing: border-box;
      }

      body {
        font-family: -apple-system, BlinkMacSystemFont, "SF Pro Display",
          "Helvetica Neue", Arial, sans-serif;
        background: rgba(255, 255, 255, 0.95);
        backdrop-filter: blur(20px);
        -webkit-backdrop-filter: blur(20px);
        border-radius: 12px;
        border: 1px solid rgba(255, 255, 255, 0.2);
        box-shadow: 0 8px 32px rgba(0, 0, 0, 0.1);
        overflow: hidden;
        user-select: none;
        -webkit-user-select: none;
      }

      .dictation-container {
        padding: 12px 16px;
        display: flex;
        align-items: center;
        gap: 12px;
        height: 48px;
        min-height: 48px;
        max-height: 48px;
      }

      .status-icon {
        width: 24px;
        height: 24px;
        border-radius: 50%;
        display: flex;
        align-items: center;
        justify-content: center;
        flex-shrink: 0;
        transition: all 0.3s ease;
      }

      .status-icon.recording {
        background: #ff9b9b;
        animation: pulse 1.5s infinite;
      }

      .status-icon.idle {
        background: #8fd4a3;
      }

      .status-icon.transforming {
        background: #ffc285;
      }

      .status-icon.complete {
        background: #8fd4a3;
      }

      .status-icon svg {
        width: 14px;
        height: 14px;
        fill: white;
      }

      .text-scroll-container {
        flex: 1;
        overflow-x: auto;
        overflow-y: hidden;
        position: relative;
        height: 24px;
        display: flex;
        align-items: center;
        scrollbar-width: none;
        -ms-overflow-style: none;
      }

      .text-scroll-container::-webkit-scrollbar {
        display: none;
      }

      .text-content {
        display: flex;
        align-items: baseline;
        gap: 8px;
        white-space: nowrap;
        min-width: 100%;
        line-height: 1.2;
      }

      .text-segment {
        font-size: 13px;
        color: #1d1d1f;
        font-weight: 400;
        display: inline-block;
        line-height: 1.2;
      }

      .text-segment.transcribed {
        color: #1d1d1f;
      }

      .text-segment.in-progress {
        color: #8e8e93;
      }

      .text-segment.in-progress::after {
        content: "|";
        animation: blink 1.2s ease-in-out infinite;
        margin-left: 1px;
        font-weight: 300;
        vertical-align: baseline;
        line-height: 1.2;
      }

      .separator {
        color: #8e8e93;
        font-size: 12px;
        margin: 0 4px;
      }

      @keyframes pulse {
        0% {
          transform: scale(1);
          opacity: 1;
        }
        50% {
          transform: scale(1.1);
          opacity: 0.8;
        }
        100% {
          transform: scale(1);
          opacity: 1;
        }
      }

      @keyframes spin {
        0% {
          transform: rotate(0deg);
        }
        100% {
          transform: rotate(360deg);
        }
      }

      @keyframes fastSpin {
        0% {
          transform: rotate(0deg);
        }
        100% {
          transform: rotate(360deg);
        }
      }

      .status-icon.transforming svg {
        animation: fastSpin 0.6s linear infinite;
      }

      @keyframes blink {
        0% {
          opacity: 1;
        }
        50% {
          opacity: 0.3;
        }
        100% {
          opacity: 1;
        }
      }

      .close-button {
        width: 20px;
        height: 20px;
        border-radius: 50%;
        background: #ffb3b3;
        border: none;
        cursor: pointer;
        display: flex;
        align-items: center;
        justify-content: center;
        transition: all 0.2s ease;
        flex-shrink: 0;
      }

      .close-button:hover {
        background: #ff9b9b;
      }

      .close-button svg {
        width: 10px;
        height: 10px;
        fill: white;
      }

      /* Dark mode support */
      @media (prefers-color-scheme: dark) {
        body {
          background: rgba(30, 30, 30, 0.95);
          border-color: rgba(255, 255, 255, 0.1);
        }

        .text-segment {
          color: #f2f2f7;
        }

        .text-segment.transcribed {
          color: #f2f2f7;
        }

        .text-segment.in-progress {
          color: #8e8e93;
        }

        .separator {
          color: #8e8e93;
        }
      }
    </style>
  </head>
  <body>
    <div id="app">
      <div class="dictation-container">
        <div class="status-icon" :class="statusIconClass">
          <!-- Microphone icon for idle and listening states using Phosphor -->
          <svg
            v-if="currentStatus === 'idle' || currentStatus === 'listening'"
            viewBox="0 0 256 256"
          >
            <path
              d="M128,176a48.05,48.05,0,0,0,48-48V64a48,48,0,0,0-96,0v64A48.05,48.05,0,0,0,128,176ZM96,64a32,32,0,0,1,64,0v64a32,32,0,0,1-64,0ZM216,128H200a72,72,0,0,1-144,0H40a8,8,0,0,0,0,16H72v16a8,8,0,0,0,16,0V144h80v16a8,8,0,0,0,16,0V144h32a8,8,0,0,0,0-16Z"
            />
          </svg>

          <!-- Loading spinner for transforming state - duo-tone -->
          <svg
            v-else-if="currentStatus === 'transforming'"
            viewBox="0 0 256 256"
          >
            <circle
              cx="128"
              cy="128"
              r="96"
              fill="none"
              stroke="rgba(255,255,255,0.3)"
              stroke-width="16"
            />
            <circle
              cx="128"
              cy="128"
              r="96"
              fill="none"
              stroke="white"
              stroke-width="16"
              stroke-linecap="round"
              stroke-dasharray="150.8"
              stroke-dashoffset="75.4"
            />
          </svg>

          <!-- Check icon for complete state using Phosphor -->
          <svg v-else-if="currentStatus === 'complete'" viewBox="0 0 256 256">
            <path
              d="m229.66,77.66-128,128a8,8,0,0,1-11.32,0l-56-56a8,8,0,0,1,11.32-11.32L96,188.69,218.34,66.34a8,8,0,0,1,11.32,11.32Z"
            />
          </svg>
        </div>

        <div class="text-scroll-container" ref="textScrollContainer">
          <div class="text-content" ref="textContent">
            <span
              v-for="(segment, index) in displaySegments"
              :key="segment.id || index"
              class="text-segment"
              :class="getSegmentClass(segment)"
            >
              {{ getSegmentDisplayText(segment) }}
            </span>
            <span
              v-if="displaySegments.length === 0"
              class="text-segment in-progress"
            >
              Listening...
            </span>
          </div>
        </div>

        <button class="close-button" @click="handleClose">
          <!-- X icon using Phosphor -->
          <svg viewBox="0 0 256 256">
            <path
              d="M205.66,194.34a8,8,0,0,1-11.32,11.32L128,139.31,61.66,205.66a8,8,0,0,1-11.32-11.32L116.69,128,50.34,61.66A8,8,0,0,1,61.66,50.34L128,116.69l66.34-66.35a8,8,0,0,1,11.32,11.32L139.31,128Z"
            />
          </svg>
        </button>
      </div>
    </div>
    <script src="./vue.js"></script>
    <script>
      const { createApp, ref, computed, onMounted, nextTick, watch } = Vue;

      createApp({
        setup() {
          // Reactive state
          const isRecording = ref(false);
          const currentStatus = ref("idle");
          const transcriptionSegments = ref([]);
          const finalText = ref("");

          // Computed properties
          const statusIconClass = computed(() => ({
            recording: currentStatus.value === "listening",
            idle: currentStatus.value === "idle",
            transforming: currentStatus.value === "transforming",
            complete: currentStatus.value === "complete",
          }));

          const hasTranscription = computed(() => {
            return transcriptionSegments.value.length > 0 || finalText.value;
          });

          const displaySegments = computed(() => {
            if (finalText.value) {
              return [
                { type: "transcribed", text: finalText.value, completed: true },
              ];
            }

            // Filter segments to only show the last in-progress segment
            const segments = transcriptionSegments.value;
            const completedSegments = segments.filter(
              (segment) => segment.type === "transcribed" && segment.completed
            );

            // Find the last in-progress segment
            const lastInProgressSegment = segments
              .filter(
                (segment) =>
                  segment.type === "inprogress" ||
                  (!segment.completed && segment.type === "transcribed")
              )
              .pop();

            // Combine completed segments with the last in-progress segment
            const result = [...completedSegments];
            if (lastInProgressSegment) {
              result.push(lastInProgressSegment);
            }

            return result;
          });

          const textContent = ref(null);
          const textScrollContainer = ref(null);

          const scrollToEnd = () => {
            if (textScrollContainer.value) {
              textScrollContainer.value.scrollLeft =
                textScrollContainer.value.scrollWidth;
            }
          };

          // Methods
          const resetTranscription = () => {
            transcriptionSegments.value = [];
            finalText.value = "";
            currentStatus.value = "listening";
          };

          const getSegmentClass = (segment) => {
            if (segment.type === "transcribed") {
              return segment.completed ? "transcribed" : "in-progress";
            }
            if (segment.type === "inprogress") return "in-progress";
            return "";
          };

          const getSegmentDisplayText = (segment) => {
            return segment.text;
          };

          const handleClose = () => {
            // Close button now hides and reloads the window instead of closing it
            window.electronAPI.closeDictationWindow();
          };

          // IPC event handlers
          const initializeDictation = (data) => {
            console.log("Initializing dictation with data:", data);
            resetTranscription();
          };

          const startRecording = () => {
            console.log("Recording started");
            isRecording.value = true;
            currentStatus.value = "listening";
            resetTranscription();
          };

          const stopRecording = () => {
            console.log("Recording stopped");
            isRecording.value = false;
            currentStatus.value = "processing";
          };

          const updateTranscription = (update) => {
            console.log("Transcription update:", update);
            transcriptionSegments.value = update.segments;
            // Show transforming status only during active transformation/injection
            if (update.status === "transforming") {
              currentStatus.value = "transforming";
            } else {
              // Show loading icon when actively receiving in-progress segments
              const hasInProgressSegments = update.segments.some(
                (segment) => segment.type === "inprogress" || !segment.completed
              );
              // Show idle microphone icon when only completed segments exist (idle recording state)
              currentStatus.value = hasInProgressSegments
                ? "listening"
                : "idle";
            }
          };

          const completeDictation = (text) => {
            console.log("Dictation complete:", text);
            finalText.value = text;
            currentStatus.value = "complete";
            transcriptionSegments.value = [
              {
                type: "transcribed",
                text: text,
                completed: true,
              },
            ];
          };

          const clearDictation = () => {
            console.log("Clearing dictation window");
            currentStatus.value = "idle";
            isRecording.value = false;
            resetTranscription();
          };

          // Watch for changes and scroll to end
          watch([displaySegments], () => {
            nextTick(() => {
              scrollToEnd();
            });
          });

          // Setup IPC listeners
          onMounted(() => {
            window.electronAPI.onInitializeDictation(initializeDictation);
            window.electronAPI.onStartRecording(startRecording);
            window.electronAPI.onStopRecording(stopRecording);
            window.electronAPI.onTranscriptionUpdate(updateTranscription);
            window.electronAPI.onDictationComplete(completeDictation);
            window.electronAPI.onDictationClear(clearDictation);

            // Prevent window from being dragged
            document.addEventListener("dragstart", (e) => e.preventDefault());
          });

          return {
            // State
            isRecording,
            currentStatus,
            transcriptionSegments,
            finalText,

            // Computed
            statusIconClass,
            hasTranscription,
            displaySegments,
            textContent,
            textScrollContainer,

            // Methods
            resetTranscription,
            getSegmentClass,
            getSegmentDisplayText,
            handleClose,
          };
        },
      }).mount("#app");
    </script>
  </body>
</html>
