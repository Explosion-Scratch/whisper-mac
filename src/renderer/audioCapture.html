<!DOCTYPE html>
<html>
  <head>
    <title>Audio Capture</title>
  </head>
  <body>
    Audio capture window
    <script>
      let audioContext = null;
      let mediaStreamSource = null;
      let processor = null;
      let analyser = null;
      let stream = null;
      let buffer = [];
      let sampleCount = 0;
      let isCapturing = false;
      let frequencyData = new Uint8Array(64);

      // Pre-initialize audio immediately on load
      async function initializeAudio() {
        try {
          console.log("Pre-initializing audio...");

          stream = await navigator.mediaDevices.getUserMedia({
            audio: {
              sampleRate: 16000,
              channelCount: 1,
              echoCancellation: true,
              noiseSuppression: true,
            },
          });

          audioContext = new AudioContext({
            sampleRate: 16000,
            latencyHint: "interactive",
          });

          // Suspend immediately after creation
          await audioContext.suspend();

          // Create media stream source
          mediaStreamSource = audioContext.createMediaStreamSource(stream);

          // Create analyser for frequency data
          analyser = audioContext.createAnalyser();
          analyser.fftSize = 128;
          analyser.smoothingTimeConstant = 0.3;

          // Create script processor for audio processing
          const bufferSize = 512; // Smoother animation: increased update rate from ~4Hz to ~31Hz
          processor = audioContext.createScriptProcessor(bufferSize, 1, 1);

          processor.onaudioprocess = (event) => {
            if (!isCapturing) return;

            const inputBuffer = event.inputBuffer;
            const inputData = inputBuffer.getChannelData(0);

            // Add samples to buffer and compute RMS level
            let sumSquares = 0;
            for (let i = 0; i < inputData.length; i++) {
              const v = inputData[i];
              buffer.push(v);
              sumSquares += v * v;
              sampleCount++;
            }

            const rms = Math.sqrt(sumSquares / Math.max(1, inputData.length));
            const level = Math.max(0, Math.min(1, rms * 3));

            // Get frequency data for wave visualization
            analyser.getByteFrequencyData(frequencyData);

            // Send enhanced audio data
            try {
              window.electronAPI.sendAudioLevel(level);
              window.electronAPI.sendAudioData({
                level: level,
                frequencies: Array.from(frequencyData.slice(0, 32)),
                timestamp: Date.now(),
              });
            } catch {}
          };

          // Connect the audio graph
          mediaStreamSource.connect(analyser);
          analyser.connect(processor);
          try {
            processor.connect(audioContext.destination);
          } catch {}

          console.log("Audio pre-initialized successfully");
        } catch (error) {
          console.error("Failed to pre-initialize audio:", error);
          window.electronAPI.sendAudioError(error.message);
        }
      }

      // Initialize audio immediately when page loads
      initializeAudio();

      // Listen for start capture command from main process
      window.electronAPI.onStartCapture(async () => {
        try {
          console.log("Starting audio capture...");

          if (!audioContext) {
            await initializeAudio();
          }

          if (audioContext.state === "suspended") {
            await audioContext.resume();
          }

          isCapturing = true;
          console.log("Audio capture started in renderer");
          window.electronAPI.sendAudioCaptureStarted();
        } catch (error) {
          console.error("Failed to start audio capture:", error);
          window.electronAPI.sendAudioError(error.message);
        }
      });

      // Listen for stop capture command from main process
      window.electronAPI.onStopCapture(() => {
        console.log("Stopping audio capture...");

        isCapturing = false;

        try {
          if (buffer.length > 0) {
            const finalArray = new Float32Array(buffer);
            window.electronAPI.sendFinalSamples(finalArray);
          }
        } catch {}

        // Suspend audio context instead of closing to keep it ready
        if (audioContext && audioContext.state === "running") {
          audioContext.suspend();
        }

        // Reset buffer
        buffer = [];
        sampleCount = 0;

        console.log("Audio capture stopped in renderer");
        window.electronAPI.sendAudioCaptureStopped();
      });
    </script>
  </body>
</html>
