<!DOCTYPE html>
<html>
  <head>
    <title>Audio Capture</title>
  </head>
  <body>
    Audio capture window
    <script>
      let audioContext = null;
      let mediaStreamSource = null;
      let workletNode = null;
      let stream = null;
      let isStreamEnabled = true;

      // Start media stream when window loads
      window.addEventListener("load", async () => {
        try {
          console.log("Starting media stream on window load...");
          await startMediaStream();
        } catch (error) {
          console.error("Failed to start media stream on load:", error);
        }
      });

      async function startMediaStream() {
        try {
          stream = await navigator.mediaDevices.getUserMedia({
            audio: {
              sampleRate: 16000,
              channelCount: 1,
              // echoCancellation: true,
              // noiseSuppression: true,
            },
          });

          console.log("Got media stream:", stream);

          audioContext = new AudioContext({
            sampleRate: 16000,
            latencyHint: "interactive",
          });

          console.log("Created audio context");

          if (audioContext.state === "suspended") {
            try {
              await audioContext.resume();
            } catch {}
          }

          // Create media stream source
          mediaStreamSource = audioContext.createMediaStreamSource(stream);

          // Load and create audio worklet processor
          await audioContext.audioWorklet.addModule("./audiopreprocessor.js");

          // Create worklet node for audio processing
          workletNode = new AudioWorkletNode(
            audioContext,
            "audiopreprocessor",
            {
              numberOfInputs: 1,
              numberOfOutputs: 1,
              outputChannelCount: [1],
            }
          );

          workletNode.port.onmessage = (event) => {
            // Only process audio if stream is enabled
            if (!isStreamEnabled) return;

            const audioData = event.data;

            // Calculate audio energy (sum of absolute values)
            let energy = 0;
            for (let i = 0; i < audioData.length; i++) {
              energy += Math.abs(audioData[i]);
            }

            console.log("Energy:", energy);
            // Only send if energy exceeds threshold (not silent)
            if (energy > 10) {
              console.log("Sending audio chunk:", audioData.length, "samples");
              window.electronAPI.sendAudioData(audioData);
            }
          };

          // Connect the audio graph
          mediaStreamSource.connect(workletNode);
          try {
            workletNode.connect(audioContext.destination);
          } catch {}

          console.log("Media stream started successfully");
        } catch (error) {
          console.error("Failed to start media stream:", error);
          throw error;
        }
      }

      function stopMediaStream() {
        console.log("Stopping media stream...");

        if (workletNode) {
          workletNode.disconnect();
          workletNode = null;
        }
        if (mediaStreamSource) {
          mediaStreamSource.disconnect();
          mediaStreamSource = null;
        }
        if (audioContext) {
          audioContext.close();
          audioContext = null;
        }
        if (stream) {
          stream.getTracks().forEach((track) => track.stop());
          stream = null;
        }

        console.log("Media stream stopped");
      }

      // Listen for start capture command from main process
      window.electronAPI.onStartCapture(async () => {
        try {
          console.log("Starting audio capture...");

          // If media stream doesn't exist, start it
          if (!stream) {
            await startMediaStream();
          }

          // Enable the stream for processing
          isStreamEnabled = true;
          console.log("Audio capture started in renderer");
          window.electronAPI.sendAudioCaptureStarted();
        } catch (error) {
          console.error("Failed to start audio capture:", error);
          window.electronAPI.sendAudioError(error.message);
        }
      });

      // Listen for stop capture command from main process
      window.electronAPI.onStopCapture(() => {
        console.log("Stopping audio capture...");

        // Disable the stream for processing but keep it running
        isStreamEnabled = false;

        console.log("Audio capture stopped in renderer");
        window.electronAPI.sendAudioCaptureStopped();
      });

      // Listen for media stream enabled/disabled command
      window.electronAPI.onSetMediaStreamEnabled((enabled) => {
        console.log(`Setting media stream enabled: ${enabled}`);
        isStreamEnabled = enabled;
      });
    </script>
  </body>
</html>
