<!DOCTYPE html>
<html>
  <head>
    <title>Audio Capture</title>
  </head>
  <body>
    Audio capture window
    <script>
      let audioContext = null;
      let mediaStreamSource = null;
      let processor = null;
      let stream = null;
      let buffer = [];
      let sampleCount = 0;

      // Listen for start capture command from main process
      window.electronAPI.onStartCapture(async () => {
        try {
          console.log("Starting audio capture...");

          stream = await navigator.mediaDevices.getUserMedia({
            audio: {
              sampleRate: 16000,
              channelCount: 1,
              // echoCancellation: true,
              // noiseSuppression: true,
            },
          });

          console.log("Got media stream:", stream);

          audioContext = new AudioContext({
            sampleRate: 16000,
            latencyHint: "interactive",
          });

          console.log("Created audio context");

          if (audioContext.state === "suspended") {
            try {
              await audioContext.resume();
            } catch {}
          }

          // Create media stream source
          mediaStreamSource = audioContext.createMediaStreamSource(stream);

          // Create script processor for audio processing
          const bufferSize = 4096;
          processor = audioContext.createScriptProcessor(bufferSize, 1, 1);

          processor.onaudioprocess = (event) => {
            const inputBuffer = event.inputBuffer;
            const inputData = inputBuffer.getChannelData(0);

            // Add samples to buffer and compute RMS level for UI
            let sumSquares = 0;
            for (let i = 0; i < inputData.length; i++) {
              const v = inputData[i];
              buffer.push(v);
              sumSquares += v * v;
              sampleCount++;
            }
            const rms = Math.sqrt(sumSquares / Math.max(1, inputData.length));
            const level = Math.max(0, Math.min(1, rms * 3));
            try {
              window.electronAPI.sendAudioLevel(level);
            } catch {}
          };

          // Connect the audio graph
          mediaStreamSource.connect(processor);
          try {
            processor.connect(audioContext.destination);
          } catch {}

          console.log("Audio capture started in renderer");
          window.electronAPI.sendAudioCaptureStarted();
        } catch (error) {
          console.error("Failed to start audio capture:", error);
          window.electronAPI.sendAudioError(error.message);
        }
      });

      // Listen for stop capture command from main process
      window.electronAPI.onStopCapture(() => {
        console.log("Stopping audio capture...");

        if (processor) {
          processor.disconnect();
          processor = null;
        }
        if (mediaStreamSource) {
          mediaStreamSource.disconnect();
          mediaStreamSource = null;
        }
        if (audioContext) {
          audioContext.close();
          audioContext = null;
        }
        if (stream) {
          stream.getTracks().forEach((track) => track.stop());
          stream = null;
        }

        try {
          if (buffer.length > 0) {
            const finalArray = new Float32Array(buffer);
            window.electronAPI.sendFinalSamples(finalArray);
          }
        } catch {}

        // Reset buffer
        buffer = [];
        sampleCount = 0;

        console.log("Audio capture stopped in renderer");
        window.electronAPI.sendAudioCaptureStopped();
      });
    </script>
  </body>
</html>
