<!DOCTYPE html>
<html>
  <head>
    <title>Audio Capture</title>
  </head>
  <body>
    Audio capture window
    <div class="energy-level"></div>
    <script>
      let audioContext = null;
      let mediaStreamSource = null;
      let processor = null;
      let analyser = null;
      let stream = null;
      let audioTrack = null;
      let buffer = [];
      let sampleCount = 0;
      let isCapturing = false;
      let frequencyData = new Uint8Array(64);

      // Pre-initialize audio immediately on load
      async function initializeAudio() {
        try {
          console.log("Pre-initializing audio...");

          // Clean up existing resources if they exist
          if (processor) {
            try {
              processor.disconnect();
            } catch {}
          }
          if (mediaStreamSource) {
            try {
              mediaStreamSource.disconnect();
            } catch {}
          }
          if (audioContext && audioContext.state !== "closed") {
            try {
              await audioContext.close();
            } catch {}
          }

          stream = await navigator.mediaDevices.getUserMedia({
            audio: {
              sampleRate: 16000,
              channelCount: 1,
              echoCancellation: true,
              noiseSuppression: true,
            },
          });

          // Get the audio track and disable it initially to prevent recording light
          audioTrack = stream.getAudioTracks()[0];
          if (audioTrack) {
            audioTrack.enabled = false;
            console.log(
              "Audio track disabled initially to prevent recording light"
            );
          }

          audioContext = new AudioContext({
            sampleRate: 16000,
            latencyHint: "interactive",
          });

          // Suspend immediately after creation
          await audioContext.suspend();

          // Create media stream source
          mediaStreamSource = audioContext.createMediaStreamSource(stream);

          // Create analyser for frequency data
          analyser = audioContext.createAnalyser();
          analyser.fftSize = 128;
          analyser.smoothingTimeConstant = 0.3;

          // Create script processor for audio processing
          const bufferSize = 512; // Smoother animation: increased update rate from ~4Hz to ~31Hz
          processor = audioContext.createScriptProcessor(bufferSize, 1, 1);

          processor.onaudioprocess = (event) => {
            if (!isCapturing) return;

            const inputBuffer = event.inputBuffer;
            const inputData = inputBuffer.getChannelData(0);

            // Add samples to buffer and compute RMS level
            let sumSquares = 0;
            for (let i = 0; i < inputData.length; i++) {
              const v = inputData[i];
              buffer.push(v);
              sumSquares += v * v;
              sampleCount++;
            }

            const rms = Math.sqrt(sumSquares / Math.max(1, inputData.length));
            const level = Math.max(0, Math.min(1, rms * 3));

            // Convert level to energy value (0-100 scale)
            const energy = level * 100;
            document.querySelector(".energy-level").textContent = energy;
            // Get frequency data for wave visualization
            analyser.getByteFrequencyData(frequencyData);

            // Only send audio data if energy is above threshold
            if (energy > 5) {
              try {
                window.electronAPI.sendAudioLevel(level);
                window.electronAPI.sendAudioData({
                  level: level,
                  frequencies: Array.from(frequencyData.slice(0, 32)),
                  timestamp: Date.now(),
                });
              } catch {}
            }
          };

          // Connect the audio graph
          mediaStreamSource.connect(analyser);
          analyser.connect(processor);
          try {
            processor.connect(audioContext.destination);
          } catch {}

          console.log("Audio pre-initialized successfully");
        } catch (error) {
          console.error("Failed to pre-initialize audio:", error);
          window.electronAPI.sendAudioError(error.message);
        }
      }

      // Initialize audio immediately when page loads
      initializeAudio();

      // Listen for start capture command from main process
      window.electronAPI.onStartCapture(async () => {
        try {
          console.log("Starting audio capture...");

          // Check if audio context exists and is valid
          if (!audioContext || audioContext.state === "closed") {
            console.log("Audio context missing or closed, reinitializing...");
            await initializeAudio();
          }

          // Check if stream is still active
          if (stream && stream.active === false) {
            console.log("Media stream inactive, reinitializing...");
            await initializeAudio();
          }

          // Enable the audio track to start recording
          if (audioTrack) {
            audioTrack.enabled = true;
            console.log(
              "Audio track enabled - recording light should now show"
            );
          }

          if (audioContext.state === "suspended") {
            await audioContext.resume();
          }

          isCapturing = true;
          console.log("Audio capture started in renderer");
          window.electronAPI.sendAudioCaptureStarted();
        } catch (error) {
          console.error("Failed to start audio capture:", error);
          window.electronAPI.sendAudioError(error.message);
        }
      });

      // Listen for stop capture command from main process
      window.electronAPI.onStopCapture(() => {
        console.log("Stopping audio capture...");

        isCapturing = false;

        // Disable the audio track to stop recording and hide recording light
        if (audioTrack) {
          audioTrack.enabled = false;
          console.log("Audio track disabled - recording light should now hide");
        }

        try {
          if (buffer.length > 0) {
            const finalArray = new Float32Array(buffer);
            window.electronAPI.sendFinalSamples(finalArray);
          }
        } catch {}

        // Suspend audio context instead of closing to keep it ready
        if (audioContext && audioContext.state === "running") {
          audioContext.suspend();
        }

        // Reset buffer
        buffer = [];
        sampleCount = 0;

        console.log("Audio capture stopped in renderer");
        window.electronAPI.sendAudioCaptureStopped();
      });
    </script>
  </body>
</html>
